{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 预测产品价格、嵌入空间可视化\n",
    "\n",
    "#### 背景：\n",
    "\n",
    "数据来自[kaggle]()，赛题为根据产品描述、类别、品牌等信息预测产品价格。  \n",
    "讨论区中已经有tf-idf + xgboost/lightgmb和rnn + keras的开源实现。  \n",
    "本文将以tensorflow作为主要工具，实现多种架构的神经网络，通过tensorboard可视化调参提升性能。\n",
    "\n",
    "#### 环境\n",
    "+ python 3.6.3\n",
    "+ tensorflow 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouzhirui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, Binarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>3</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>3</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Target</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand_name                                      category_name  \\\n",
       "0        NaN                                  Men/Tops/T-shirts   \n",
       "1      Razer  Electronics/Computers & Tablets/Components & P...   \n",
       "2     Target                        Women/Tops & Blouses/Blouse   \n",
       "\n",
       "   item_condition_id                                   item_description  \\\n",
       "0                  3                                 No description yet   \n",
       "1                  3  This keyboard is in great condition and works ...   \n",
       "2                  1  Adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \n",
       "0  MLB Cincinnati Reds T Shirt Size XL   10.0         1      NaN       0.0  \n",
       "1     Razer BlackWidow Chroma Keyboard   52.0         0      NaN       1.0  \n",
       "2                       AVA-VIV Blouse   10.0         1      NaN       2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_path = '../input/'\n",
    "mac_path = '/Users/zhouzhirui/data/Mercari_Price_Forcast/'\n",
    "\n",
    "def load_data(path):\n",
    "    train = pd.read_table(path+'train.tsv')\n",
    "    test = pd.read_table(path+'test.tsv')\n",
    "    merge = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "    return merge\n",
    "merge = load_data(mac_path)\n",
    "merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge = merge[merge.train_id.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理数据\n",
    "+ fill missing\n",
    "+ convert upper-case to lower-case\n",
    "+ encoding\n",
    "+ onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>condition_2</th>\n",
       "      <th>condition_3</th>\n",
       "      <th>condition_4</th>\n",
       "      <th>condition_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men/tops/t-shirts</td>\n",
       "      <td>missing</td>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808</td>\n",
       "      <td>2937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electronics/computers &amp; tablets/components &amp; p...</td>\n",
       "      <td>this keyboard is in great condition and works ...</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86</td>\n",
       "      <td>3615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>women/tops &amp; blouses/blouse</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1255</td>\n",
       "      <td>4242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       category_name  \\\n",
       "0                                  men/tops/t-shirts   \n",
       "1  electronics/computers & tablets/components & p...   \n",
       "2                        women/tops & blouses/blouse   \n",
       "\n",
       "                                    item_description  \\\n",
       "0                                            missing   \n",
       "1  this keyboard is in great condition and works ...   \n",
       "2  adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \\\n",
       "0  mlb cincinnati reds t shirt size xl   10.0         1      NaN       0.0   \n",
       "1     razer blackwidow chroma keyboard   52.0         0      NaN       1.0   \n",
       "2                       ava-viv blouse   10.0         1      NaN       2.0   \n",
       "\n",
       "   category  brand  condition_2  condition_3  condition_4  condition_5  \n",
       "0       808   2937            0            1            0            0  \n",
       "1        86   3615            0            1            0            0  \n",
       "2      1255   4242            0            0            0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onehot_condition(dataset):\n",
    "    onehot = pd.get_dummies(merge.condition, drop_first=True, prefix='condition')\n",
    "    dataset = pd.concat([dataset, onehot], axis=1).drop('condition', axis=1)\n",
    "    return dataset\n",
    "\n",
    "def handle_missing(dataset):\n",
    "    dataset.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.loc[dataset.item_description == 'No description yet', 'item_description'] = 'missing'\n",
    "    return dataset\n",
    "\n",
    "def upper2lower(dataset):\n",
    "    for (col, dtype) in dataset.dtypes.iteritems():\n",
    "        if dtype == 'object':\n",
    "            dataset[col] = dataset[col].str.lower()\n",
    "    return dataset\n",
    "\n",
    "def label_encoding(dataset):\n",
    "    le_category = LabelEncoder()\n",
    "    dataset['category'] = le_category.fit_transform(dataset.category_name)\n",
    "    le_brand = LabelEncoder()\n",
    "    dataset['brand'] = le_brand.fit_transform(dataset.brand_name)\n",
    "    dataset['condition'] = dataset['item_condition_id']\n",
    "    del dataset['brand_name'], dataset['item_condition_id']\n",
    "    return dataset, le_category, le_brand\n",
    "\n",
    "merge = handle_missing(merge)\n",
    "merge = upper2lower(merge)\n",
    "merge, le_category, le_brand = label_encoding(merge)\n",
    "merge = onehot_condition(merge)\n",
    "merge.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge = merge.sample(frac=1).reset_index(drop=True)\n",
    "dtrain = merge.iloc[:1470000,:].reset_index(drop=True)\n",
    "dtest = merge.iloc[1470000:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练样本迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(dataset, batch_size):\n",
    "    data = dataset[['brand','category','price','shipping','condition_2','condition_3','condition_4','condition_5']].values\n",
    "    np.random.shuffle(data)\n",
    "    datalen = data.shape[0]\n",
    "    idx = 0\n",
    "    while idx * batch_size < datalen:\n",
    "        brand = data[idx*batch_size:(idx+1)*batch_size, 0].reshape(-1, 1)\n",
    "        category = data[idx*batch_size:(idx+1)*batch_size, 1].reshape(-1, 1)\n",
    "        price = np.log1p(data[idx*batch_size:(idx+1)*batch_size, 2]).reshape(-1, 1)\n",
    "        num = data[idx*batch_size:(idx+1)*batch_size, 3:]\n",
    "        idx += 1\n",
    "        yield brand, category, num, price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证集数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(dataset):\n",
    "    data = dataset[['brand','category','price','shipping','condition_2','condition_3','condition_4','condition_5']].values\n",
    "    brand = data[:, 0].reshape(-1, 1)\n",
    "    category = data[:, 1].reshape(-1, 1)\n",
    "    price = np.log1p(data[:, 2]).reshape(-1, 1)\n",
    "    num = data[:, 3:]\n",
    "    return brand, category, num, price\n",
    "\n",
    "val_brand, val_category, val_num, val_price = get_val_data(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model1 without text feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.005, 'epochs': 8, 'batchsize': 10000, 'keep_prob': 0.7, 'logdir': '/Users/zhouzhirui/Desktop/log1', 'brand_num': 4810, 'brand_embed_dim': 30, 'category_num': 1288, 'category_embed_dim': 20}\n"
     ]
    }
   ],
   "source": [
    "class Param(object):        \n",
    "    def __setattr__(self, attr, value):\n",
    "        self.__dict__[attr] = value\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "    __repr__ = __str__\n",
    "\n",
    "param = Param()\n",
    "param.lr = 0.005\n",
    "param.epochs = 8\n",
    "param.batchsize = 10000\n",
    "param.keep_prob = 0.7\n",
    "param.logdir = '/Users/zhouzhirui/Desktop/log1'\n",
    "param.brand_num = merge.brand.max() + 1\n",
    "param.brand_embed_dim = 30  # brand类别过多，添加embedding layer降维\n",
    "param.category_num = merge.category.max() + 1\n",
    "param.category_embed_dim = 20  # 同理brand\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model1(object):\n",
    "    \"\"\"无文本建模模型\"\"\"\n",
    "    def __init__(self, param):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "            \n",
    "            with tf.name_scope('inputs'):\n",
    "                self.add_input()\n",
    "                \n",
    "            with tf.name_scope('brand_embedding'):\n",
    "                self.brand_embedding = self.add_brand_embedding(param.brand_num, param.brand_embed_dim)\n",
    "                \n",
    "            with tf.name_scope('category_embedding'):\n",
    "                self.category_embedding = self.add_category_embedding(param.category_num, param.category_embed_dim)\n",
    "                \n",
    "            self.main = tf.concat([self.input_num, \n",
    "                                   tf.reshape(self.brand_embedding, [-1, param.brand_embed_dim]), \n",
    "                                   tf.reshape(self.category_embedding, [-1, param.category_embed_dim])], axis=1)\n",
    "            \n",
    "            with tf.name_scope('dense1'):\n",
    "                self.dense1 = self.add_dence_layer(inputs=self.main, \n",
    "                                                   input_size=param.category_embed_dim + param.brand_embed_dim + 5, \n",
    "                                                   output_size=64, \n",
    "                                                   activation=tf.nn.relu, \n",
    "                                                   keep_prob=self.keep_prob)\n",
    "                \n",
    "            with tf.name_scope('dense2'):\n",
    "                self.dense2 = self.add_dence_layer(inputs=self.dense1, \n",
    "                                                   input_size=64, \n",
    "                                                   output_size=32, \n",
    "                                                   activation=tf.nn.relu, \n",
    "                                                   keep_prob=self.keep_prob)\n",
    "            \n",
    "                \n",
    "            with tf.name_scope('output_layer'):\n",
    "                self.output = self.add_dence_layer(inputs=self.dense2,\n",
    "                                                   input_size=32,\n",
    "                                                   output_size=1,\n",
    "                                                   activation='false', \n",
    "                                                   keep_prob='false')\n",
    "            with tf.name_scope('loss'):\n",
    "                self.loss = tf.losses.mean_squared_error(self.target, self.output)\n",
    "\n",
    "            with tf.name_scope('optimizer'):\n",
    "                self.train = tf.train.AdamOptimizer(param.lr).minimize(self.loss)\n",
    "\n",
    "            self.init = tf.global_variables_initializer()\n",
    "\n",
    "               \n",
    "    def add_input(self):\n",
    "        self.input_brand = tf.placeholder(tf.int32, [None, 1], name='brand')\n",
    "        self.input_category = tf.placeholder(tf.int32, [None, 1], name='category')\n",
    "        self.input_num = tf.placeholder(tf.float32, [None, 5], name='num')\n",
    "        self.target = tf.placeholder(tf.float32, [None,1], name='price')\n",
    "        \n",
    "    \n",
    "    def add_brand_embedding(self, input_dim, output_dim):\n",
    "        self.brand_embed_matrix = tf.Variable(tf.random_uniform([input_dim, output_dim], -1., 1.0), name='brand_embed_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(self.brand_embed_matrix, self.input_category, name='brand_embed_lookup')\n",
    "        return embeding\n",
    "    \n",
    "    def add_category_embedding(self, input_dim, output_dim):\n",
    "        self.category_embed_matrix = tf.Variable(tf.random_uniform([input_dim, output_dim], -1., 1.0), name='category_embed_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(self.category_embed_matrix, self.input_category, name='category_embed_lookup')\n",
    "        return embeding\n",
    "    \n",
    "    def add_dence_layer(self, inputs, input_size, output_size, activation=None, keep_prob='false'):\n",
    "        W = tf.Variable(tf.random_normal(dtype=tf.float32, shape=[input_size, output_size], mean=0, stddev=0.1), name='W')\n",
    "        b = tf.Variable(tf.zeros(dtype=tf.float32, shape=[1, output_size]) + 0.1, name='b')\n",
    "        output = tf.matmul(inputs, W) + b\n",
    "        if activation != 'false':\n",
    "            output = tf.nn.relu(output)\n",
    "        if keep_prob != 'false':\n",
    "            output = tf.nn.dropout(output, keep_prob)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  step0 : train_loss:8.5754 ,val_loss:8.7049, embeddsum:29.96\n",
      "epoch:0  step20 : train_loss:0.5533 ,val_loss:0.5786, embeddsum:145.46\n",
      "epoch:0  step40 : train_loss:0.4689 ,val_loss:0.4707, embeddsum:149.95\n",
      "epoch:0  step60 : train_loss:0.4328 ,val_loss:0.4303, embeddsum:162.12\n",
      "epoch:0  step80 : train_loss:0.4229 ,val_loss:0.4270, embeddsum:173.30\n",
      "epoch:0  step100 : train_loss:0.4126 ,val_loss:0.4161, embeddsum:182.48\n",
      "epoch:0  step120 : train_loss:0.4091 ,val_loss:0.4158, embeddsum:181.68\n",
      "epoch:0  step140 : train_loss:0.4061 ,val_loss:0.4131, embeddsum:184.66\n",
      "epoch:1  step0 : train_loss:0.4125 ,val_loss:0.4154, embeddsum:185.13\n",
      "epoch:1  step20 : train_loss:0.4162 ,val_loss:0.4138, embeddsum:187.81\n",
      "epoch:1  step40 : train_loss:0.3987 ,val_loss:0.4110, embeddsum:188.94\n",
      "epoch:1  step60 : train_loss:0.3938 ,val_loss:0.4101, embeddsum:186.92\n",
      "epoch:1  step80 : train_loss:0.3957 ,val_loss:0.4088, embeddsum:185.51\n",
      "epoch:1  step100 : train_loss:0.4040 ,val_loss:0.4110, embeddsum:186.48\n",
      "epoch:1  step120 : train_loss:0.4042 ,val_loss:0.4070, embeddsum:187.15\n",
      "epoch:1  step140 : train_loss:0.3950 ,val_loss:0.4075, embeddsum:185.48\n",
      "epoch:2  step0 : train_loss:0.4000 ,val_loss:0.4073, embeddsum:185.52\n",
      "epoch:2  step20 : train_loss:0.3997 ,val_loss:0.4091, embeddsum:183.49\n",
      "epoch:2  step40 : train_loss:0.4022 ,val_loss:0.4095, embeddsum:185.19\n",
      "epoch:2  step60 : train_loss:0.3911 ,val_loss:0.4045, embeddsum:184.39\n",
      "epoch:2  step80 : train_loss:0.4024 ,val_loss:0.4083, embeddsum:188.26\n",
      "epoch:2  step100 : train_loss:0.3988 ,val_loss:0.4041, embeddsum:190.32\n",
      "epoch:2  step120 : train_loss:0.3986 ,val_loss:0.4048, embeddsum:188.84\n",
      "epoch:2  step140 : train_loss:0.4006 ,val_loss:0.4058, embeddsum:187.26\n",
      "epoch:3  step0 : train_loss:0.4022 ,val_loss:0.4010, embeddsum:186.95\n",
      "epoch:3  step20 : train_loss:0.3937 ,val_loss:0.4072, embeddsum:187.97\n",
      "epoch:3  step40 : train_loss:0.3960 ,val_loss:0.4072, embeddsum:191.77\n",
      "epoch:3  step60 : train_loss:0.3990 ,val_loss:0.4085, embeddsum:192.48\n",
      "epoch:3  step80 : train_loss:0.4016 ,val_loss:0.4032, embeddsum:193.33\n",
      "epoch:3  step100 : train_loss:0.3946 ,val_loss:0.4053, embeddsum:193.21\n",
      "epoch:3  step120 : train_loss:0.3953 ,val_loss:0.4021, embeddsum:192.99\n",
      "epoch:3  step140 : train_loss:0.4038 ,val_loss:0.4015, embeddsum:194.25\n",
      "epoch:4  step0 : train_loss:0.3914 ,val_loss:0.3995, embeddsum:194.17\n",
      "epoch:4  step20 : train_loss:0.3976 ,val_loss:0.4012, embeddsum:194.31\n",
      "epoch:4  step40 : train_loss:0.3903 ,val_loss:0.4009, embeddsum:193.52\n",
      "epoch:4  step60 : train_loss:0.3910 ,val_loss:0.3991, embeddsum:193.56\n",
      "epoch:4  step80 : train_loss:0.3873 ,val_loss:0.4018, embeddsum:194.03\n",
      "epoch:4  step100 : train_loss:0.3923 ,val_loss:0.4004, embeddsum:196.97\n",
      "epoch:4  step120 : train_loss:0.3892 ,val_loss:0.3994, embeddsum:198.14\n",
      "epoch:4  step140 : train_loss:0.3947 ,val_loss:0.4021, embeddsum:198.85\n",
      "epoch:5  step0 : train_loss:0.4027 ,val_loss:0.3975, embeddsum:199.16\n",
      "epoch:5  step20 : train_loss:0.3809 ,val_loss:0.4007, embeddsum:200.67\n",
      "epoch:5  step40 : train_loss:0.4073 ,val_loss:0.4027, embeddsum:200.77\n",
      "epoch:5  step60 : train_loss:0.3729 ,val_loss:0.4008, embeddsum:200.19\n",
      "epoch:5  step80 : train_loss:0.3918 ,val_loss:0.3992, embeddsum:202.24\n",
      "epoch:5  step100 : train_loss:0.3961 ,val_loss:0.3990, embeddsum:199.31\n",
      "epoch:5  step120 : train_loss:0.3983 ,val_loss:0.3983, embeddsum:198.36\n",
      "epoch:5  step140 : train_loss:0.3786 ,val_loss:0.3970, embeddsum:197.99\n",
      "epoch:6  step0 : train_loss:0.3816 ,val_loss:0.4006, embeddsum:196.55\n",
      "epoch:6  step20 : train_loss:0.3923 ,val_loss:0.3998, embeddsum:193.51\n",
      "epoch:6  step40 : train_loss:0.3756 ,val_loss:0.3968, embeddsum:192.29\n",
      "epoch:6  step60 : train_loss:0.3769 ,val_loss:0.4002, embeddsum:191.59\n",
      "epoch:6  step80 : train_loss:0.4012 ,val_loss:0.3998, embeddsum:190.03\n",
      "epoch:6  step100 : train_loss:0.3842 ,val_loss:0.3988, embeddsum:189.20\n",
      "epoch:6  step120 : train_loss:0.4040 ,val_loss:0.3961, embeddsum:188.30\n",
      "epoch:6  step140 : train_loss:0.3762 ,val_loss:0.3968, embeddsum:187.38\n",
      "epoch:7  step0 : train_loss:0.3938 ,val_loss:0.3959, embeddsum:186.83\n",
      "epoch:7  step20 : train_loss:0.3874 ,val_loss:0.3970, embeddsum:186.73\n",
      "epoch:7  step40 : train_loss:0.3933 ,val_loss:0.3982, embeddsum:187.16\n",
      "epoch:7  step60 : train_loss:0.3884 ,val_loss:0.3972, embeddsum:183.69\n",
      "epoch:7  step80 : train_loss:0.3972 ,val_loss:0.3965, embeddsum:181.72\n",
      "epoch:7  step100 : train_loss:0.3931 ,val_loss:0.3958, embeddsum:181.08\n",
      "epoch:7  step120 : train_loss:0.3895 ,val_loss:0.3966, embeddsum:180.35\n",
      "epoch:7  step140 : train_loss:0.3877 ,val_loss:0.3946, embeddsum:183.01\n"
     ]
    }
   ],
   "source": [
    "model1 = Model1(param)\n",
    "tf.summary.histogram(name='brand_embedding',values=model1.brand_embed_matrix)\n",
    "tf.summary.histogram(name='category_embedding',values=model1.category_embed_matrix)\n",
    "tf.summary.scalar('loss',model1.loss)\n",
    "summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(param.logdir, model1.graph)\n",
    "# val_writer = tf.summary.FileWriter(param.logdir+'/val', model1.graph)\n",
    "sess = tf.Session(graph=model1.graph)\n",
    "sess.run(model1.init)\n",
    "\n",
    "for i in range(param.epochs):\n",
    "    k = 0\n",
    "    for (brand, category, num, price) in batch_generator(dtrain, param.batchsize):\n",
    "        _, loss = sess.run([model1.train, model1.loss], {model1.input_brand:brand, \n",
    "                                                        model1.input_category:category,\n",
    "                                                        model1.input_num:num, \n",
    "                                                        model1.target:price,\n",
    "                                                        model1.keep_prob:param.keep_prob})\n",
    "        if k%20 == 0:\n",
    "            val_loss = sess.run(model1.loss, {model1.input_brand:val_brand, \n",
    "                                                        model1.input_category:val_category,\n",
    "                                                        model1.input_num:val_num, \n",
    "                                                        model1.target:val_price,\n",
    "                                                        model1.keep_prob:1.})\n",
    "            train_loss = sess.run(model1.loss, {model1.input_brand:brand, \n",
    "                                                        model1.input_category:category,\n",
    "                                                        model1.input_num:num, \n",
    "                                                        model1.target:price,\n",
    "                                                        model1.keep_prob:1.})\n",
    "            print('epoch:%d  step%d : train_loss:%.4f ,val_loss:%.4f, embeddsum:%.2f'%(i, k, train_loss, val_loss, sess.run(model1.brand_embed_matrix).sum()))\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge['brand_name'] = le_brand.inverse_transform(merge.brand)\n",
    "id2brand = dict(zip(range(4810), le_brand.classes_))\n",
    "brand2id = dict(zip(le_brand.classes_,range(4810)))\n",
    "embedding_matrix = sess.run(model1.brand_embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67389876, -0.70933992,  0.58079666, -0.21463154,  0.55771631,\n",
       "        0.45473605, -0.45238081,  0.2506023 ,  0.05044049, -0.42083871,\n",
       "        0.56253678,  0.08243759, -0.51152676, -0.07393313,  0.02964799,\n",
       "        0.22313081, -0.89522874,  0.07326837, -0.68000102,  0.46859783,\n",
       "        0.02646305, -0.13218412,  0.0137408 ,  0.13657908, -0.29262793,\n",
       "        0.55516356,  0.08805592, -0.41509423,  0.63190967, -0.12040908], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[brand2id['adidas neo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adidas\n",
      "all sport\n",
      "lite brix\n",
      "canon\n",
      "aqua\n",
      "old spice\n",
      "john paul pet\n",
      "xelement\n",
      "equipment\n",
      "basic editions\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(np.sum(np.square(embedding_matrix - vec), axis=1))[:10]:\n",
    "    print(id2brand[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(x, y):\n",
    "    return np.sqrt(np.square(x-y).sum())\n",
    "    \n",
    "def similar(brand_name, n=5):\n",
    "    brand_vec = embedding_matrix[brand2id[brand_name]]\n",
    "    \n",
    "    print(pd.Series(np.dot(embedding_matrix, brand_vec), index=le_brand.classes_).sort_values(ascending=False)[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adidas          8.770928\n",
      "acne studios    5.847715\n",
      "mother          5.129402\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "similar(\"adidas\", n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class A():\n",
    "    a = 3\n",
    "    def good(self):\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a.good()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'reuse'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c9ffab28b805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scope1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scope1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'reuse'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.variable_scope(\"scope1\"):\n",
    "    w1 = tf.Variable(\"w1\", shape=[])\n",
    "    w2 = tf.Variable(0.0, name=\"w2\")\n",
    "with tf.variable_scope(\"scope1\", reuse=True):\n",
    "    w1_p = tf.get_variable(\"w1\", shape=[])\n",
    "    w2_p = tf.Variable(1.0, name=\"w2\")\n",
    "\n",
    "print(w1 is w1_p, w2 is w2_p)\n",
    "#输出\n",
    "#True  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
