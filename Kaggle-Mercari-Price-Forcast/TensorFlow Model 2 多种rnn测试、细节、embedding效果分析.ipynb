{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouzhirui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, Binarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def lazy_property(func):\n",
    "    attr = '_lazy_' + func.__name__\n",
    "\n",
    "    @property\n",
    "    @wraps(func)\n",
    "    def wrapper(self):\n",
    "        if not hasattr(self, attr):\n",
    "            setattr(self, attr, func(self))\n",
    "        return getattr(self, attr)\n",
    "    return wrapper\n",
    "\n",
    "class ParamModel1(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'model1'\n",
    "        self.lr = 0.05\n",
    "        self.keep_prob = 0.8\n",
    "        self.epochs = 2\n",
    "        self.batch_size = 5000\n",
    "        self.val_size = 2000\n",
    "        self.vocabulary_size = 10000\n",
    "        self.max_seq_len = 200\n",
    "        self.hidden_units = 16\n",
    "        self.seq_embed_dim = 60\n",
    "        self.log_path = '/Users/zhouzhirui/Desktop/log/%s/'%self.name\n",
    "        self.save_path = '/Users/zhouzhirui/Desktop/model_save'\n",
    "    def __setattr__(self, attr, value):\n",
    "        self.__dict__[attr] = value\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "    __repr__ = __str__\n",
    "\n",
    "p1 = ParamModel1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data ..\n",
      "测试，只取100000条数据\n",
      "handle missing ..\n",
      "upper2lower ..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>condition</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing</td>\n",
       "      <td>men/tops/t-shirts</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>razer</td>\n",
       "      <td>electronics/computers &amp; tablets/components &amp; p...</td>\n",
       "      <td>3</td>\n",
       "      <td>this keyboard is in great condition and works ...</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target</td>\n",
       "      <td>women/tops &amp; blouses/blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                                           category  condition  \\\n",
       "0  missing                                  men/tops/t-shirts          3   \n",
       "1    razer  electronics/computers & tablets/components & p...          3   \n",
       "2   target                        women/tops & blouses/blouse          1   \n",
       "\n",
       "                                         description  \\\n",
       "0                                            missing   \n",
       "1  this keyboard is in great condition and works ...   \n",
       "2  adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \n",
       "0  mlb cincinnati reds t shirt size xl   10.0         1      NaN       0.0  \n",
       "1     razer blackwidow chroma keyboard   52.0         0      NaN       1.0  \n",
       "2                       ava-viv blouse   10.0         1      NaN       2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_path = '../input/'\n",
    "mac_path = '/Users/zhouzhirui/data/Mercari_Price_Forcast/'\n",
    "\n",
    "def handle_missing(dataset):\n",
    "    dataset.category.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.description.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.loc[dataset.description == 'No description yet', 'description'] = 'missing'\n",
    "    return dataset\n",
    "\n",
    "def upper2lower(dataset):\n",
    "    for (col, dtype) in dataset.dtypes.iteritems():\n",
    "        if dtype == 'object':\n",
    "            dataset[col] = dataset[col].str.lower()\n",
    "    return dataset\n",
    "\n",
    "def load_data(path):\n",
    "    print('load data ..')\n",
    "    train = pd.read_table(path+'train.tsv')\n",
    "    test = pd.read_table(path+'test.tsv')\n",
    "    merge = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "    merge.rename(columns={\n",
    "        'brand_name':'brand',\n",
    "        'category_name':'category',\n",
    "        'item_condition_id':'condition',\n",
    "        'item_description':'description'\n",
    "    }, inplace=True)\n",
    "    print('测试，只取100000条数据')\n",
    "    merge = merge[:100000]\n",
    "    print('handle missing ..')\n",
    "    merge = handle_missing(merge)\n",
    "    print('upper2lower ..')\n",
    "    merge = upper2lower(merge)\n",
    "    train = merge[merge.train_id.notnull()].reset_index(drop=True)\n",
    "    test = merge[merge.train_id.isnull()].reset_index(drop=True)\n",
    "    return train, test\n",
    "train, test = load_data(mac_path)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>condition</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>seq_name</th>\n",
       "      <th>seq_category</th>\n",
       "      <th>seq_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1231</td>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>missing</td>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2367, 8086, 7463, 74, 103, 7, 201]</td>\n",
       "      <td>[77, 43, 74, 75]</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1544</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>this keyboard is in great condition and works ...</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8184, 2634]</td>\n",
       "      <td>[61, 923, 845, 3092, 1393]</td>\n",
       "      <td>[34, 2634, 11, 8, 50, 17, 1, 259, 66, 19, 1219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1813</td>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[7902, 268]</td>\n",
       "      <td>[2, 43, 76, 268]</td>\n",
       "      <td>[736, 72, 10, 5, 5527, 12, 243, 1, 5, 1050, 13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  category  condition  \\\n",
       "0   1231       571          2   \n",
       "1   1544        79          2   \n",
       "2   1813       939          0   \n",
       "\n",
       "                                         description  \\\n",
       "0                                            missing   \n",
       "1  this keyboard is in great condition and works ...   \n",
       "2  adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \\\n",
       "0  mlb cincinnati reds t shirt size xl   10.0         1      NaN       0.0   \n",
       "1     razer blackwidow chroma keyboard   52.0         0      NaN       1.0   \n",
       "2                       ava-viv blouse   10.0         1      NaN       2.0   \n",
       "\n",
       "                              seq_name                seq_category  \\\n",
       "0  [2367, 8086, 7463, 74, 103, 7, 201]            [77, 43, 74, 75]   \n",
       "1                         [8184, 2634]  [61, 923, 845, 3092, 1393]   \n",
       "2                          [7902, 268]            [2, 43, 76, 268]   \n",
       "\n",
       "                                     seq_description  \n",
       "0                                               [80]  \n",
       "1  [34, 2634, 11, 8, 50, 17, 1, 259, 66, 19, 1219...  \n",
       "2  [736, 72, 10, 5, 5527, 12, 243, 1, 5, 1050, 13...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text2seq(dtrain, dtest, vocabulary_size):\n",
    "    tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "    tokenizer.fit_on_texts(np.hstack([dtrain.category, dtrain.description, dtrain.name]))\n",
    "    for col in ['name', 'category', 'description']:\n",
    "        dtrain['seq_'+col] = tokenizer.texts_to_sequences(dtrain[col])\n",
    "        dtest['seq_'+col] = tokenizer.texts_to_sequences(dtest[col])\n",
    "    return dtrain, dtest, tokenizer\n",
    "\n",
    "train, test, _ = text2seq(train, test, p1.vocabulary_size)\n",
    "\n",
    "def label_encoding(dtrain, dtest):\n",
    "    le = LabelEncoder()\n",
    "    for col in ['category', 'brand', 'condition']:\n",
    "        le.fit(np.hstack([dtrain[col], dtest[col]]))\n",
    "        dtrain[col] = le.transform(dtrain[col])\n",
    "        dtest[col] = le.transform(dtest[col])\n",
    "    return dtrain, dtest\n",
    "\n",
    "train, test = label_encoding(train, test)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val_test(dtrain, dtest, val_size):\n",
    "    dtrain = dtrain.sample(frac=1.0).reset_index(drop=True)\n",
    "    dval = dtrain.iloc[:val_size,:].reset_index(drop=True)\n",
    "    dtrain = dtrain.iloc[val_size:,:].reset_index(drop=True)\n",
    "    return dtrain, dval, dtest\n",
    "\n",
    "train, val, test = get_train_val_test(train, test, p1.val_size)\n",
    "\n",
    "def gen_batch_data(dataset, batch_size):\n",
    "    dataset = dataset.sample(frac=1.0).reset_index(drop=True)\n",
    "    max_step = dataset.shape[0] // batch_size\n",
    "    for step in range(max_step):\n",
    "        sub = dataset.iloc[step*batch_size : (step+1)*batch_size, :]\n",
    "        yield sub\n",
    "\n",
    "def gen_tf_data(subdata, max_len):\n",
    "    seq_desc_len = subdata['seq_description'].apply(len).values\n",
    "    seq_desc = tf.keras.preprocessing.sequence.pad_sequences(subdata['seq_description'], maxlen=max_len, padding='post')\n",
    "    price = np.log1p(subdata['price']).values\n",
    "    return seq_desc, seq_desc_len, price\n",
    "\n",
    "val_seq_desc, val_seq_desc_len, val_price = gen_tf_data(subdata=val, max_len=p1.max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Inputs1(object):\n",
    "    def __init__(self, param):\n",
    "        with tf.name_scope('feature') as ns:\n",
    "            self.seq_desc = tf.placeholder(dtype=tf.int32, shape=[None, param.max_seq_len], name='seq_desc')\n",
    "            self.seq_desc_len = tf.placeholder(dtype=tf.int32, shape=[None], name='seq_desc_len')\n",
    "        with tf.name_scope('control'):\n",
    "            self.keep_prob = tf.placeholder(dtype=tf.float32 ,name='keep_prob')\n",
    "        with tf.name_scope('label'):\n",
    "            self.label = tf.placeholder(dtype=tf.float32, shape=[None], name='price')\n",
    "#             tf.summary.histogram('price', self.label)\n",
    "\n",
    "            \n",
    "\n",
    "class Model1(object):\n",
    "    def __init__(self, mode, param, inputs):\n",
    "        self.mode = mode\n",
    "        self.param = param\n",
    "        self.inputs = inputs\n",
    "        self.predict\n",
    "        self.loss\n",
    "        self.train\n",
    "    \n",
    "    def _add_embed_layer(self, name, inputs, inputs_dim, outputs_dim):\n",
    "        with tf.name_scope(name+'_layer'):\n",
    "            with tf.variable_scope(name) as vs:\n",
    "                initializer = tf.initializers.random_normal()\n",
    "                matrix = tf.get_variable(name=name+'_matrix', shape=[inputs_dim, outputs_dim], initializer=initializer)\n",
    "                embed = tf.nn.embedding_lookup(matrix, inputs)\n",
    "        return embed\n",
    "    \n",
    "    def _add_dense_layer(self, name, inputs, hidden_units, act=None, keep_prob=1.):\n",
    "        with tf.name_scope(name) as ns:\n",
    "            w = tf.get_variable(\n",
    "                name+'_W', \n",
    "                shape=[inputs.get_shape()[1], hidden_units] ,\n",
    "                initializer=tf.initializers.random_normal(dtype=tf.float32, mean=0., stddev=1.)\n",
    "            )\n",
    "            b = tf.get_variable(\n",
    "                name+'_b', \n",
    "                shape=[1, hidden_units],\n",
    "                initializer=tf.initializers.zeros()\n",
    "            )\n",
    "            wx_plus_b = tf.matmul(inputs, w) + b\n",
    "            if act:\n",
    "                wx_plus_b = act(b)\n",
    "            wx_plus_b = tf.nn.dropout(wx_plus_b, keep_prob)\n",
    "            tf.summary.histogram('W', w)\n",
    "            tf.summary.histogram('b', b)\n",
    "            return wx_plus_b\n",
    "            \n",
    "\n",
    "    @lazy_property\n",
    "    def predict(self):\n",
    "        desc_seq_embed = self._add_embed_layer(\n",
    "            name='seq_embed', \n",
    "            inputs=self.inputs.seq_desc, \n",
    "            inputs_dim=self.param.vocabulary_size+1,   #配置词典大小\n",
    "            outputs_dim=self.param.seq_embed_dim     #配置嵌入空间\n",
    "        )\n",
    "        self._cell = tf.nn.rnn_cell.BasicLSTMCell(self.param.hidden_units)\n",
    "        if self.mode == 'train':\n",
    "            batch_size = self.param.batch_size\n",
    "        elif self.mode == 'val':\n",
    "            batch_size = self.param.val_size\n",
    "        elif self.mode == 'predict':\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            raise ValueError(\"wrone model mode\")\n",
    "        self._init_state = self._cell.zero_state(batch_size, dtype=tf.float32)\n",
    "            \n",
    "        outputs, state = tf.nn.dynamic_rnn(\n",
    "            self._cell, \n",
    "            desc_seq_embed, \n",
    "            initial_state=self._init_state, \n",
    "#             sequence_length=self.inputs.seq_desc_len\n",
    "        )\n",
    "        outputs = tf.reshape(outputs[:,-1,:], [-1, self.param.hidden_units])\n",
    "        price = self._add_dense_layer('output', outputs, 1)\n",
    "        price = tf.reshape(price, [-1])\n",
    "        return price\n",
    "    \n",
    "    @lazy_property\n",
    "    def loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "#             loss = tf.losses.mean_squared_error(self.predict, self.inputs.label)\n",
    "            loss = tf.reduce_mean(tf.square(tf.subtract(self.predict, self.inputs.label)), axis=-1)\n",
    "#             tf.summary.scalar('loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    @lazy_property\n",
    "    def train(self):\n",
    "        with tf.variable_scope('train_op'):\n",
    "            optimizer = tf.train.AdamOptimizer(self.param.lr)\n",
    "            train_op = optimizer.minimize(self.loss)\n",
    "        return train_op\n",
    "    \n",
    "    \n",
    "    def reset_size(self, n):\n",
    "        self._init_state = self._cell.zero_state(n, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = Inputs1(p1)\n",
    "    with tf.name_scope('training'):\n",
    "        train_model = Model1(mode='train', param=p1, inputs=inputs)\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    with tf.name_scope('val'):\n",
    "        val_model = Model1(mode='val', param=p1, inputs=inputs)\n",
    "    merge = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(p1.log_path, graph=graph)\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 2 train loss: 3.21 ; val loss: 2.31, step cost time 3.1\n",
      "epoch 1 step 4 train loss: 0.72 ; val loss: 0.65, step cost time 3.0\n",
      "epoch 1 step 6 train loss: 0.88 ; val loss: 0.93, step cost time 2.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-454f91199035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_desc_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_desc_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                             inputs.keep_prob:p1.keep_prob})\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhouzhirui/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhouzhirui/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhouzhirui/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhouzhirui/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhouzhirui/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph).as_default() as sess:\n",
    "    sess.run(init)\n",
    "    k=0\n",
    "    for i in range(4):\n",
    "        for sub in gen_batch_data(dataset=train, batch_size=p1.batch_size):\n",
    "            t1 = time.time()\n",
    "            seq_desc, seq_desc_len, price = gen_tf_data(subdata=sub, max_len=p1.max_seq_len)\n",
    "            _, loss_i, rs_train = sess.run([train_model.train, train_model.loss, merge], \n",
    "                                 feed_dict={inputs.seq_desc:seq_desc, \n",
    "                                            inputs.seq_desc_len:seq_desc_len,\n",
    "                                            inputs.label:price,\n",
    "                                            inputs.keep_prob:p1.keep_prob})\n",
    "            \n",
    "            k+=1\n",
    "            t2 = time.time()\n",
    "            tcost = t2-t1\n",
    "            if k%2 == 0:\n",
    "                loss, rs_test = sess.run([val_model.loss, merge],\n",
    "                               feed_dict={inputs.seq_desc:val_seq_desc, \n",
    "                                            inputs.seq_desc_len:val_seq_desc_len,\n",
    "                                            inputs.label:val_price,\n",
    "                                            inputs.keep_prob:1.})\n",
    "#                 writer.add_summary(rs_test, k)\n",
    "#                 writer.add_summary(rs_train, k)\n",
    "                print('epoch %d step %d train loss: %.2f ; val loss: %.2f, step cost time %.1f'%(i+1, k, loss_i, loss, tcost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "1. dynamic_rnn  设置seq——len 反而速度慢？而且收敛也慢了\n",
    "2. cell的zero state问题 ——已经解决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_mean = tf.reduce_mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
