{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouzr/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "path = '/home/zhouzr/data/tianchi/user_location_predict/original_data/'\n",
    "os.chdir(path)\n",
    "\n",
    "train = pd.read_csv('./训练数据-ccf_first_round_user_shop_behavior.csv')\n",
    "shop = pd.read_csv('./训练数据-ccf_first_round_shop_info.csv')\n",
    "test = pd.read_csv('./AB榜测试集-evaluation_public.csv')\n",
    "\n",
    "train = pd.merge(train, shop[['shop_id','mall_id']], on='shop_id', how='left')\n",
    "sample = pd.concat([train, test])\n",
    "sample['time_stamp'] = pd.to_datetime(sample.time_stamp)\n",
    "sample.insert(0,'sample_id',range(sample.shape[0]))\n",
    "mall_id_list = shop.mall_id.unique()\n",
    "del train, test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outlier_filter(df, col, min_filter=0.005, max_filter=0.995):\n",
    "    min_outlier = np.percentile(df[col], min_filter*100)\n",
    "    max_outlier = np.percentile(df[col], max_filter*100)\n",
    "    result = df[(df[col] < max_outlier) & (df[col] > min_outlier)].reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wifi_filter_dict(df, filter_rate=None, filter_num=None):\n",
    "    wifi_infos = df['wifi_infos']\n",
    "    wifi_count = {}\n",
    "    for wifi_infos_i in wifi_infos:\n",
    "        wifi_infos_i = [wifi.split('|') for wifi in wifi_infos_i.split(';')]\n",
    "        for wifi in wifi_infos_i:\n",
    "            if wifi[0] in wifi_count:\n",
    "                wifi_count[wifi[0]] += 1\n",
    "            else:\n",
    "                wifi_count[wifi[0]] = 1\n",
    "    if filter_rate:\n",
    "        filter_num = np.percentile(pd.Series(wifi_count).values, filter_rate*100)\n",
    "    if filter_num:\n",
    "        filter_num = filter_num\n",
    "    wifi_dict = {}\n",
    "    for k, v in wifi_count.items():\n",
    "        if v > filter_num:\n",
    "            wifi_dict[k] = 0\n",
    "    return wifi_dict\n",
    "\n",
    "def wifi_power_ext(df, wifi_dict):   \n",
    "    wifi_infos = df.wifi_infos\n",
    "    result = []\n",
    "    for wifi_infos_i in wifi_infos:\n",
    "        wifi_infos_i = [wifi.split('|') for wifi in wifi_infos_i.split(';')]\n",
    "        result_i = wifi_dict.copy()\n",
    "        for wifi in wifi_infos_i:\n",
    "            if wifi[0] in wifi_dict:\n",
    "                result_i[wifi[0]] = float(wifi[1]) + 120\n",
    "        result.append(result_i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result\n",
    "\n",
    "def gen_train_test(df, mall_id, test=True, test_rate=0.2):\n",
    "    df_mall = df[df.mall_id == mall_id].reset_index(drop=True)\n",
    "    df1 = df_mall[df_mall.shop_id.notnull()].reset_index(drop=True)\n",
    "    df2 = df_mall[df_mall.shop_id.isnull()].reset_index(drop=True)\n",
    "    if test:\n",
    "        test_sample_id = random.sample(df1.sample_id.tolist(), int(test_rate * df1.shape[0]))\n",
    "        train = df1[-df1.sample_id.isin(test_sample_id)].reset_index(drop=True).drop(['sample_id','mall_id'], axis=1)\n",
    "        test = df1[df1.sample_id.isin(test_sample_id)].reset_index(drop=True).drop(['sample_id','mall_id'], axis=1)\n",
    "    else:\n",
    "        train = df1.drop(['sample_id','mall_id'], axis=1)\n",
    "        test = df2.drop(['sample_id','mall_id'], axis=1)\n",
    "    \n",
    "\n",
    "    # latitude/longitude outlier processing\n",
    "    train = outlier_filter(train, 'latitude')\n",
    "    train = outlier_filter(train, 'longitude')\n",
    "    train_size = train.shape[0]   \n",
    "    test_size = test.shape[0]\n",
    "    scaler = MinMaxScaler()\n",
    "    space_train = scaler.fit_transform(train[['latitude', 'longitude']])\n",
    "    space_test = scaler.transform(test[['latitude', 'longitude']])\n",
    "    # time\n",
    "    weekday_train = train.time_stamp.dt.weekday.values.reshape(train_size,1)\n",
    "    weekday_test = test.time_stamp.dt.weekday.reshape(test_size,1)\n",
    "    hour_train = train.time_stamp.dt.hour.values.reshape(train_size,1)\n",
    "    hour_test = test.time_stamp.dt.hour.reshape(test_size,1)\n",
    "    # user_id\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.concatenate([train.user_id, test.user_id]))\n",
    "    userid_train = le.transform(train.user_id).reshape(train_size,1)\n",
    "    userid_test = le.transform(test.user_id).reshape(test_size,1)\n",
    "    # wifi\n",
    "    wifi_dict = wifi_filter_dict(train, filter_rate=0.95)\n",
    "    wifi_train = wifi_power_ext(train, wifi_dict)\n",
    "    wifi_test = wifi_power_ext(test, wifi_dict)\n",
    "    \n",
    "    train_x = np.concatenate([space_train, weekday_train, hour_train, userid_train, wifi_train], axis=1)\n",
    "    test_x = np.concatenate([space_test, weekday_test, hour_test, userid_test, wifi_test], axis=1)\n",
    "    \n",
    "    #label encode\n",
    "    class_le = LabelEncoder()\n",
    "    class_le.fit(np.concatenate([train.shop_id.values, test.shop_id.fillna('Null').values]))\n",
    "    \n",
    "    train_y = class_le.transform(train.shop_id)\n",
    "    test_y = class_le.transform(test.shop_id.fillna('Null'))\n",
    "    \n",
    "#     train_y = train.shop_id.values\n",
    "#     test_y = test.shop_id.values\n",
    "    test_row_id = test.row_id.values\n",
    "    return train_x,train_y,test_x,test_y,test_row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouzr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/home/zhouzr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y,test_x,test_y,test_row_id = gen_train_test(sample, mall_id_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52,\n",
       "       53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "       70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x, train_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "param = {'objective':'multi:softmax','num_class':84}\n",
    "model = xgb.train(param,dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8854886475814413"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, model.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, eval_metric='auc',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90621915103652517"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90621915103652517"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99806446183623665"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, rf.predict(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88910825929582105"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, rf.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'booster':'gbtree',\n",
    "            'eta':0.1,\n",
    "            'objective':'multi:softmax',\n",
    "            'max_depth':10,\n",
    "            'num_class':np.unique(train_y).size+1\n",
    "#             'subsample':1.0,\n",
    "#             'min_child_weight':5,\n",
    "#             'colsample_bytree':0.2,\n",
    "#             'scale_pos_weight':0.1,\n",
    "#             'eval_metric':'auc',\n",
    "#             'gamma':0.2,            \n",
    "#             'lambda':300\n",
    "}\n",
    "model = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
