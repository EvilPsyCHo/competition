{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "\"\"\"\n",
    "@author : zhirui zhou\n",
    "@contact: evilpsycho42@gmail.com\n",
    "@time   : 2019/11/6 13:49\n",
    "\"\"\"\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class SimpleSeq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, target_dim, hidden_size, activation='Tanh', dropout=0.0):\n",
    "        super(SimpleSeq2Seq, self).__init__()\n",
    "        self.target_dim = target_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = nn.LSTM(target_dim, hidden_size, num_layers=1, bias=True, batch_first=True)\n",
    "        self.decoder = nn.LSTM(target_dim, hidden_size, num_layers=1, bias=True, batch_first=True)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, target_dim),\n",
    "            getattr(nn, activation)(),\n",
    "            nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        batch, dec_lens, _ = dec_inputs.shape\n",
    "        enc_outputs, enc_hidden = self.encoder(enc_inputs)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_outputs, _ = self.decoder(dec_inputs, dec_hidden)\n",
    "        preds = self.out(dec_outputs)\n",
    "        return preds\n",
    "\n",
    "    def predict(self, enc_inputs, predict_steps):\n",
    "        with torch.no_grad():\n",
    "            batch, _, _ = enc_inputs.shape\n",
    "            enc_outputs, enc_hidden = self.encoder(enc_inputs)\n",
    "            dec_inputs = enc_inputs[:, -1, :].unsqueeze(1)\n",
    "            dec_hidden = enc_hidden\n",
    "            preds = torch.zeros(batch, predict_steps, 1)\n",
    "            for i in range(predict_steps):\n",
    "                dec_outputs, dec_hidden = self.decoder(dec_inputs, dec_hidden)\n",
    "                dec_inputs = self.out(dec_outputs)\n",
    "                preds[:, i] = dec_inputs\n",
    "            return preds\n",
    "    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TorchSimpleSeriesDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, series, enc_lens, dec_lens):\n",
    "        self.s = series.astype('float32')\n",
    "        self.el = enc_lens\n",
    "        self.dl = dec_lens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.s) - self.el - self.dl + 1\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        enc_inputs = self.s[item: item + self.el].reshape(-1, 1)\n",
    "        dec_inputs = self.s[item + self.el - 1: item + self.el + self.dl - 1].reshape(-1, 1)\n",
    "        dec_outputs = self.s[item + self.el: item + self.el + self.dl].reshape(-1, 1)\n",
    "        return (enc_inputs, dec_inputs), dec_outputs\n",
    "\n",
    "\n",
    "def walk_forward_split(series_index, n_test, enc_lens, dec_lens):\n",
    "    train_index = series_index[: -n_test]\n",
    "    valid_index = series_index[-(dec_lens + n_test - 1 + enc_lens):]\n",
    "    return train_index, valid_index\n",
    "\n",
    "\n",
    "def log_sin_curve(total_lens):\n",
    "    source = np.sin(np.arange(total_lens)) + np.log(np.arange(1, total_lens + 1))\n",
    "    noise = np.random.normal(0, 0.5, size=total_lens)\n",
    "    x = source + noise\n",
    "    return x, source\n",
    "\n",
    "\n",
    "def create_dataset(x, enc_lens, dec_lens, n_valid, n_test, normalization=True):\n",
    "    idxes = np.arange(len(x))\n",
    "    train_idx, tmp_idx = walk_forward_split(idxes, n_test+n_valid, enc_lens, dec_lens)\n",
    "    valid_idx, test_idx = walk_forward_split(tmp_idx, n_test, enc_lens, dec_lens)\n",
    "    x_train, x_valid, x_test = x[train_idx], x[valid_idx], x[test_idx]\n",
    "\n",
    "    if normalization:\n",
    "        mu = x_train.mean()\n",
    "        std = x_train.std()\n",
    "        x_train = (x_train - mu) / std\n",
    "        x_valid = (x_valid - mu) / std\n",
    "        x_test = (x_test - mu) / std\n",
    "\n",
    "    train = TorchSimpleSeriesDataSet(x_train, enc_lens, dec_lens)\n",
    "    valid = TorchSimpleSeriesDataSet(x_valid, enc_lens, dec_lens)\n",
    "    test = TorchSimpleSeriesDataSet(x_test, enc_lens, dec_lens)\n",
    "    return train, valid, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, source = log_sin_curve(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lens = 20\n",
    "dec_lens = 10\n",
    "n_valid =10\n",
    "n_test = 10\n",
    "\n",
    "trainset, validset, testset = create_dataset(x, enc_lens, dec_lens, n_valid, n_test)\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "traindl = DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "validdl = DataLoader(validset, shuffle=False, batch_size=batch_size)\n",
    "testdl = DataLoader(testset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = SimpleSeq2Seq(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_train import Learner, AdamW\n",
    "from fastai.basic_data import DataBunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch = DataBunch(traindl, validdl, testdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(bunch, model, loss_func=nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleSeq2Seq(\n",
       "  (encoder): LSTM(1, 10, batch_first=True)\n",
       "  (decoder): LSTM(1, 10, batch_first=True)\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=1, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Learner' object has no attribute 'lr_find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f01cf5c6afa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Learner' object has no attribute 'lr_find'"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49292627]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(testdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.221285</td>\n",
       "      <td>0.363092</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218922</td>\n",
       "      <td>0.369334</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.216972</td>\n",
       "      <td>0.371345</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.368116</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.214972</td>\n",
       "      <td>0.376091</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213489</td>\n",
       "      <td>0.378226</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>0.354735</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.211516</td>\n",
       "      <td>0.386417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.210286</td>\n",
       "      <td>0.407192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.210018</td>\n",
       "      <td>0.352613</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209290</td>\n",
       "      <td>0.370050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.208019</td>\n",
       "      <td>0.377346</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.207005</td>\n",
       "      <td>0.360001</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.206298</td>\n",
       "      <td>0.358362</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.205810</td>\n",
       "      <td>0.405407</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.205045</td>\n",
       "      <td>0.383921</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.204084</td>\n",
       "      <td>0.386253</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.202977</td>\n",
       "      <td>0.390387</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.390708</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.201090</td>\n",
       "      <td>0.397330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.201227</td>\n",
       "      <td>0.368492</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>0.406033</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.199447</td>\n",
       "      <td>0.387332</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.197783</td>\n",
       "      <td>0.402364</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.197375</td>\n",
       "      <td>0.409430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.196838</td>\n",
       "      <td>0.371099</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.196307</td>\n",
       "      <td>0.416135</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.429951</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.194720</td>\n",
       "      <td>0.437050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.193478</td>\n",
       "      <td>0.404493</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
