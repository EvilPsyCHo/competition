{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def score2(pm, pp, plant):\n",
    "    plant_power = {\n",
    "        1: 10,\n",
    "        2: 10,\n",
    "        3: 40,\n",
    "        4: 50\n",
    "    }\n",
    "    threshold = plant_power[plant] * 0.03\n",
    "    index = pm >= threshold\n",
    "    return np.abs(pm[index] - pp[index]).sum() / (np.sum(index) * plant_power[plant])\n",
    "\n",
    "\n",
    "def load_dataset(plant):\n",
    "    print(f'loading plant {plant} data')\n",
    "    train = pd.read_csv(f'../data/train_{plant}.csv', parse_dates=[\"时间\"]).drop_duplicates().reset_index(drop=True)\n",
    "    test = pd.read_csv(f'../data/test_{plant}.csv', parse_dates=[\"时间\"])\n",
    "    train.columns = ['time', 'irr', 'ws', 'wd', 'temp', 'pr', 'hm', 'mirr', 'power']\n",
    "    test.columns = ['id', 'time', 'irr', 'ws', 'wd', 'temp', 'pr', 'hm']\n",
    "    data = pd.concat([train, test])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading plant 1 data\n"
     ]
    }
   ],
   "source": [
    "p1 = load_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = p1.id.isnull()\n",
    "test = p1.power.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1['wd'] = MinMaxScaler((-1, 1)).fit_transform(p1['wd'].values.reshape(-1,1))\n",
    "power_scaler = StandardScaler(with_mean=0, with_std=1.).fit(p1[train]['power'].values.reshape(-1,1))\n",
    "p1.loc[train, 'power'] = power_scaler.transform(p1.loc[train, 'power'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SingleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.GRU(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.unlinear = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        x, hn = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.unlinear(x[-1, :, :].squeeze())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(x, seq, features):\n",
    "    train = x[x.id.isnull()].reset_index(drop=True)\n",
    "    test = x[x.id.notnull()].reset_index(drop=True)\n",
    "    train_size, test_size = train.shape[0], test.shape[0]\n",
    "    train_x, test_x = [], []\n",
    "    train_y = train['power'].values[seq:]\n",
    "    for i in range(seq, train_size):\n",
    "        train_x.append(x.iloc[i-seq: i][features].values)\n",
    "    for i in range(train_size, test_size + train_size):\n",
    "        test_x.append(x.iloc[i-seq: i][features].values)\n",
    "    return np.stack(train_x, axis=1), np.stack(test_x, axis=1), train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y = get_train_test(p1, 100, features=['hm', 'irr', 'pr', 'temp', 'wd', 'ws'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = torch.tensor(train_x).float()\n",
    "test_x = torch.tensor(test_x).float()\n",
    "train_y = torch.tensor(train_y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(x, y, batch_size, shuffle=True):\n",
    "    n_sample = x.shape[1]\n",
    "    idx = np.array(range(n_sample))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    iterations = n_sample // batch_size\n",
    "    for step in range(iterations):\n",
    "        yield (x[:, idx[batch_size*step: batch_size*(step+1)], :], \n",
    "               y[idx[batch_size*step: batch_size*(step+1)]], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, step: 256, loss:  1.1385\n",
      "epoch: 1, step: 512, loss:  1.1077\n",
      "epoch: 1, step: 768, loss:  1.0450\n",
      "epoch: 1, step: 1024, loss:  1.0742\n",
      "epoch: 1, step: 1280, loss:  1.1098\n",
      "epoch: 1, step: 1536, loss:  1.0479\n",
      "epoch: 1, step: 1792, loss:  1.0892\n",
      "epoch: 1, step: 2048, loss:  1.0946\n",
      "epoch: 1, step: 2304, loss:  1.1023\n",
      "epoch: 1, step: 2560, loss:  1.0716\n",
      "epoch: 1, step: 2816, loss:  1.0840\n",
      "epoch: 1, step: 3072, loss:  1.1201\n",
      "epoch: 1, step: 3328, loss:  1.0894\n",
      "epoch: 1, step: 3584, loss:  1.0165\n",
      "epoch: 1, step: 3840, loss:  1.0980\n",
      "epoch: 1, step: 4096, loss:  1.0694\n",
      "epoch: 1, step: 4352, loss:  1.0870\n",
      "epoch: 1, step: 4608, loss:  1.0981\n",
      "epoch: 1, step: 4864, loss:  1.0864\n",
      "epoch: 1, step: 5120, loss:  1.0953\n",
      "epoch: 1, step: 5376, loss:  1.0854\n",
      "epoch: 1, step: 5632, loss:  1.0608\n",
      "epoch: 1, step: 5888, loss:  1.0574\n",
      "epoch: 1, step: 6144, loss:  1.0893\n",
      "epoch: 1, step: 6400, loss:  1.1208\n",
      "epoch: 1, step: 6656, loss:  1.0964\n",
      "epoch: 1, step: 6912, loss:  1.0266\n",
      "epoch: 1, step: 7168, loss:  1.0996\n",
      "epoch: 1, step: 7424, loss:  1.1025\n",
      "epoch: 1, step: 7680, loss:  1.1100\n",
      "epoch: 1, step: 7936, loss:  1.1467\n",
      "epoch: 1, step: 8192, loss:  1.0623\n",
      "epoch: 1, step: 8448, loss:  1.1162\n",
      "epoch: 1, step: 8704, loss:  1.0951\n",
      "epoch: 1, step: 8960, loss:  1.0951\n",
      "epoch: 1, step: 9216, loss:  1.1284\n",
      "epoch: 1, step: 9472, loss:  1.0912\n",
      "epoch: 1, step: 9728, loss:  1.0614\n",
      "epoch: 1, step: 9984, loss:  1.0560\n",
      "epoch: 1, step: 10240, loss:  1.1139\n",
      "epoch: 1, step: 10496, loss:  1.0571\n",
      "epoch: 1, step: 10752, loss:  1.1079\n",
      "epoch: 1, step: 11008, loss:  1.0932\n",
      "epoch: 1, step: 11264, loss:  1.0833\n",
      "epoch: 1, step: 11520, loss:  1.0951\n",
      "epoch: 1, step: 11776, loss:  1.0840\n",
      "epoch: 1, step: 12032, loss:  1.1079\n",
      "epoch: 1, step: 12288, loss:  1.0774\n",
      "epoch: 1, step: 12544, loss:  1.0854\n",
      "epoch: 1, step: 12800, loss:  1.0893\n",
      "epoch: 1, step: 13056, loss:  1.0751\n",
      "epoch: 1, step: 13312, loss:  1.1056\n",
      "epoch: 1, step: 13568, loss:  1.1088\n",
      "epoch: 1, step: 13824, loss:  1.1240\n",
      "epoch: 1, step: 14080, loss:  1.0722\n",
      "epoch: 1, step: 14336, loss:  1.0584\n",
      "epoch: 1, step: 14592, loss:  1.1485\n",
      "epoch: 1, step: 14848, loss:  1.1032\n",
      "epoch: 1, step: 15104, loss:  1.0844\n",
      "epoch: 1, step: 15360, loss:  1.0697\n",
      "epoch: 1, step: 15616, loss:  1.0515\n",
      "epoch: 1, step: 15872, loss:  1.1034\n",
      "epoch: 1, step: 16128, loss:  1.0744\n",
      "epoch: 1, step: 16384, loss:  1.0227\n",
      "epoch: 1, step: 16640, loss:  1.0879\n",
      "epoch: 2, step: 256, loss:  1.2456\n",
      "epoch: 2, step: 512, loss:  1.1204\n",
      "epoch: 2, step: 768, loss:  1.0919\n",
      "epoch: 2, step: 1024, loss:  1.0845\n",
      "epoch: 2, step: 1280, loss:  1.0987\n",
      "epoch: 2, step: 1536, loss:  1.0723\n",
      "epoch: 2, step: 1792, loss:  1.1215\n",
      "epoch: 2, step: 2048, loss:  1.0687\n",
      "epoch: 2, step: 2304, loss:  1.0686\n",
      "epoch: 2, step: 2560, loss:  1.0985\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "SEQLEN = 100\n",
    "INPUT_SIZE = 10\n",
    "batch_size = 4\n",
    "\n",
    "lstm = SingleLSTM(6, 300)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "torch.nn.L1Loss\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "loss_record = 0\n",
    "loss_total = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    for (batch_x, batch_y, step) in generate_batch(train_x, train_y, batch_size):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = lstm(batch_x)\n",
    "        loss = loss_func(pred_y, batch_y)\n",
    "        loss_record += loss\n",
    "        loss.backward()\n",
    "        loss_total.append(loss)\n",
    "        optimizer.step()\n",
    "        if step % 4**4 == 0 and step > 0:\n",
    "            loss_record /= 4**4\n",
    "            loss_total.append(loss_record)\n",
    "            print(f'epoch: {epoch}, step: {step}, loss: {loss_record: .4f}')\n",
    "            loss_record = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
